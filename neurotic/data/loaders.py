from typing import Text, Optional, List, Union

import pandas as pd
import numpy as np
import tensorflow as tf

from tensorflow import Tensor
from tensorflow.python.data.ops.dataset_ops import Dataset
from tensorflow.keras.preprocessing import timeseries_dataset_from_array
from pandas import DataFrame


class DatasetLoader:
    """
    DatasetLoaders perform custom logic to build and return tensorflow
    Datasets. To implement your own subclass, you must override the abstract
    self.on_load method.

    An example of a loader is the SingleStepTimeSeriesDataFrameLoader. This
    loader returns a Dataset whose inputs and labels are configured for a
    RNN, which operates on a fixed window size and predicts a fixed length
    step into the future.
    """

    def __init__(self, *args, **kwargs):
        self._ds: Dataset = None
        self._memoized_first: Tensor = None

    @property
    def ds(self) -> Dataset:
        """
        The tensorflow Dataset generated by the most recent self.load call.
        """
        return self._ds

    @property
    def first(self) -> Optional[Tensor]:
        """
        If self.load has been called, the first batch contained in the
        generated Dataset is returned; otherwise, None.
        """
        if self._ds is None:
            return None
        if self._memoized_first is None:
            self._memoized_first = next(iter(self._ds))
        return self._memoized_first

    def load(self, *args, **kwargs) -> Dataset:
        """
        Perform custom logic to create and return a tensorflow Dataset.
        """
        self._ds = self.on_load(*args, **kwargs)
        return self._ds

    def reset(self):
        """
        Clear internal state generated by a previous call to self.load.
        """
        self._memoized_first = None
        self._ds = None

    def on_load(self, *args, **kwargs) -> Union[Dataset, List[Dataset]]:
        """
        Generate and return a tensorflow Dataset. Override in subclass.
        """
        raise NotImplementedError()


class TimeSeriesDataFrameLoader(DatasetLoader):
    def on_load(
        self,
        df: Union[DataFrame, List[DataFrame]]
    ) -> Union[Dataset, List[Dataset]]:
        raise NotImplementedError()


class SingleStepTimeSeriesDataFrameLoader(TimeSeriesDataFrameLoader):
    """
    The SingleStepTimeSeriesDataFrameLoader is useful for time series
    prediction, where you'd like to predict one or more final values in a
    given window of time series data.
    
    For example, if you'd like to predict the last 1 hour in a 10 hour
    period, then your window size would be 10 and step size 1. This would
    result in a prediction of the final 10th hour based on the previous 9
    hours. In code, this would look like:

    ```python
    key = 'predicted_feature_name'
    period = 10
    step = 1

    loader = SingleStepTimeSeriesDataFrameLoader(key, period, step)
    ds = loader.load(df)  # `df` being your "features" dataframe
    ```

    """

    def __init__(
        self,
        key: Text,
        period: int,
        step: int = 1,
        batch_size: int = 32
    ):
        """
        `period`: number of time steps we look back at to predict
        `step`: number data points at end of period to predict
        """
        assert period > 0
        assert step > 0

        self.key = key
        self.window = period + step
        self.period = period
        self.batch_size = batch_size
        self.step = 1
    
    def on_load(
        self,
        df: Union[DataFrame, List[DataFrame]]
    ) -> Union[Dataset, List[Dataset]]:
        """
        Return one or more Datasets, where each batch consists of
        `self.period` number of input feature rows and `self.step` number of
        target labels to approximate/predict.
        """
        # normalize `df` arg to a list of DataFrames
        if isinstance(df, DataFrame):
            dfs = [df]
            return_many = False
        else:
            return_many = True
            dfs = df

        # index of the feature column we want to predict
        key_idx = dfs[0].columns.get_loc(self.key)

        def as_inputs_and_labels(x):
            """
            This function is used as a map, applied to each element in the
            generated Dataset. It takes each feature tensor, `x` in the
            caller Dataset and replaces it with a tensor tuple of the form
            (inputs, labels), where inputs contains the "period" portion of
            the time window, and labels holds the target value we're trying
            to predict.
            """
            n = self.period
            inputs = x[:, :n, :]
            labels = x[:, self.step:, :]
            labels = tf.stack([labels[:, :, key_idx]], axis=-1)
            inputs.set_shape([None, n, None])
            labels.set_shape([None, n, None])
            return (inputs, labels)

        # build a Dataset for each DataFrame
        datasets = []
        for df in dfs: 
            ds = timeseries_dataset_from_array(
                data=np.array(df, dtype=np.float32),
                targets=None,
                sequence_length=self.window,
                sequence_stride=1,
                shuffle=False,
                batch_size=self.batch_size,
            ).map(as_inputs_and_labels)
            datasets.append(ds)

        # return one or a list of the built Datasets
        return datasets if return_many else datasets[0]